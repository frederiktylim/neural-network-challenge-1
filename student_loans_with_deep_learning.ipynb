{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries for data preparation\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "url = \"https://static.bc-edx.com/ai/ail-v-1-0/m18/lms/datasets/student-loans.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Step 2: Display the first few rows to understand the structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Step 3: Check for missing values and data types\n",
    "print(\"Checking for missing values and data types:\")\n",
    "print(data.info())\n",
    "\n",
    "# Step 4: Define features (X) and target (y)\n",
    "X = data.drop(columns=[\"credit_ranking\"])\n",
    "y = data[\"credit_ranking\"]\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Step 6: Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Output to confirm preprocessing\n",
    "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Shape of X_test_scaled:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b068419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries for building and training the neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(units=10, activation=\"relu\", input_dim=X_train_scaled.shape[1]),\n",
    "    Dense(units=5, activation=\"relu\"),\n",
    "    Dense(units=1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Step 2: Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Step 3: Train the model with validation split\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 4: Evaluate the model on the testing dataset\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 5: Plot training history for loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Save the model\n",
    "model.save(\"student_loans.keras\")\n",
    "print(\"Model saved as 'student_loans.keras'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required library for evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Reload the saved model\n",
    "loaded_model = tf.keras.models.load_model(\"student_loans.keras\")\n",
    "print(\"Model successfully loaded.\")\n",
    "\n",
    "# Step 2: Make predictions on the testing data\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Step 3: Generate and display the classification report\n",
    "report = classification_report(y_test, predictions_binary, target_names=[\"Low Credit\", \"High Credit\"])\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64c39b",
   "metadata": {},
   "source": [
    "\n",
    "### Recommendation System Discussion\n",
    "\n",
    "1. **Data to Collect**:  \n",
    "   To build a recommendation system, we would collect data such as a student's academic history, income level, credit score, loan amount, repayment period, and field of study.  \n",
    "   This data is relevant because it directly impacts the ability to repay loans and helps provide personalized loan options.\n",
    "\n",
    "2. **Filtering Method**:  \n",
    "   The system would likely use **content-based filtering**. This is because the recommendations would depend on the specific attributes of the student (e.g., credit score, income). Collaborative filtering may not work well here due to the variability in student profiles.\n",
    "\n",
    "3. **Challenges**:  \n",
    "   - **Data Privacy**: Collecting sensitive financial data requires stringent privacy measures to ensure data security.  \n",
    "   - **Bias in Recommendations**: The system could inadvertently favor certain groups over others if the training data is not diverse, leading to ethical concerns.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
